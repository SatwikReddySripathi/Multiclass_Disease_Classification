{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Processing Data Entry csv file"
      ],
      "metadata": {
        "id": "BA_YwdWVjlf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjuMDMsTOWcq",
        "outputId": "da4b102e-baa3-4b13-d8fe-4f7b4322474a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import random\n",
        "import pandas as pd\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "hy2pEX9QO5-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file_path = '/content/drive/My Drive/MLOPs Project/Data_Entry.csv'\n",
        "csv_data = pd.read_csv(csv_file_path)"
      ],
      "metadata": {
        "id": "SCncEid1O9BI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-Eo7o1JOSD5",
        "outputId": "87549b64-1e33-4beb-c55b-01f5c834ba0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label Frequencies:\n",
            "Cardiomegaly: 2776\n",
            "Emphysema: 2516\n",
            "Effusion: 13317\n",
            "No Finding: 60361\n",
            "Hernia: 227\n",
            "Infiltration: 19894\n",
            "Mass: 5782\n",
            "Nodule: 6331\n",
            "Atelectasis: 11559\n",
            "Pneumothorax: 5302\n",
            "Pleural_Thickening: 3385\n",
            "Pneumonia: 1431\n",
            "Fibrosis: 1686\n",
            "Edema: 2303\n",
            "Consolidation: 4667\n",
            "                 Label  Frequency\n",
            "4               Hernia        227\n",
            "11           Pneumonia       1431\n",
            "12            Fibrosis       1686\n",
            "13               Edema       2303\n",
            "1            Emphysema       2516\n",
            "0         Cardiomegaly       2776\n",
            "10  Pleural_Thickening       3385\n",
            "14       Consolidation       4667\n",
            "9         Pneumothorax       5302\n",
            "6                 Mass       5782\n",
            "7               Nodule       6331\n",
            "8          Atelectasis      11559\n",
            "2             Effusion      13317\n",
            "5         Infiltration      19894\n",
            "3           No Finding      60361\n"
          ]
        }
      ],
      "source": [
        "label_freq = defaultdict(int)\n",
        "images_per_label = defaultdict(list)\n",
        "\n",
        "for _, row in csv_data.iterrows():\n",
        "    image_index = row['Image Index']\n",
        "    labels = row['Finding Labels'].split('|')\n",
        "\n",
        "    for label in labels:\n",
        "        label = label.strip()\n",
        "        label_freq[label] += 1\n",
        "        images_per_label[label].append(image_index)\n",
        "\n",
        "print(\"Label Frequencies:\")\n",
        "for label, freq in label_freq.items():\n",
        "    print(f\"{label}: {freq}\")\n",
        "\n",
        "label_freq_df = pd.DataFrame(list(label_freq.items()), columns=['Label', 'Frequency'])\n",
        "label_freq_df = label_freq_df.sort_values(by='Frequency')\n",
        "print(label_freq_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_labels = sorted(label_freq, key=label_freq.get)\n",
        "print(\"Labels sorted by frequency:\", sorted_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSsFI1iiP1Rl",
        "outputId": "22f1fd71-51b5-4760-921f-a3cc6ca60b03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels sorted by frequency: ['Hernia', 'Pneumonia', 'Fibrosis', 'Edema', 'Emphysema', 'Cardiomegaly', 'Pleural_Thickening', 'Consolidation', 'Pneumothorax', 'Mass', 'Nodule', 'Atelectasis', 'Effusion', 'Infiltration', 'No Finding']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_sample_size = 900\n",
        "\n",
        "selected_images = set()\n",
        "selected_images_per_label = defaultdict(list)\n",
        "label_count = defaultdict(int)\n",
        "\n",
        "start= time.time()\n",
        "\n",
        "for label in sorted_labels:\n",
        "    images = images_per_label[label]\n",
        "    required_samples = min(target_sample_size - label_count[label], len(images))\n",
        "\n",
        "    if required_samples > 0:\n",
        "        sampled_images = random.sample(images, required_samples)\n",
        "\n",
        "        selected_images.update(sampled_images)\n",
        "        selected_images_per_label[label].extend(sampled_images)\n",
        "\n",
        "        for sampled_image in sampled_images: # Updating the label count for the other classes\n",
        "            image_labels = csv_data[csv_data['Image Index'] == sampled_image]['Finding Labels'].values[0].split('|')\n",
        "            for image_label in image_labels:\n",
        "                image_label = image_label.strip()\n",
        "                label_count[image_label] += 1\n",
        "\n",
        "end = time.time()\n",
        "print(f\"Time taken for sampling through the csv file: {end - start} seconds\")\n",
        "\n",
        "print(\"Selected Images Count:\")\n",
        "for label, count in label_count.items():\n",
        "    print(f\"{label}: {count}\")\n",
        "\n",
        "print(f\"Total selected images: {len(selected_images)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWzDFAfcQDM_",
        "outputId": "d732f13a-59ab-4dbd-b5de-47442634cf45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken for sampling through the csv file: 98.20579957962036 seconds\n",
            "Selected Images Count:\n",
            "Hernia: 244\n",
            "Atelectasis: 1056\n",
            "Pneumothorax: 958\n",
            "Nodule: 900\n",
            "Consolidation: 1001\n",
            "Infiltration: 1755\n",
            "Pneumonia: 1071\n",
            "Pleural_Thickening: 1035\n",
            "Mass: 957\n",
            "Effusion: 1480\n",
            "Emphysema: 1046\n",
            "Cardiomegaly: 960\n",
            "Fibrosis: 999\n",
            "Edema: 989\n",
            "No Finding: 900\n",
            "Total selected images: 7501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "In the previous step, the duplicates are already handled. However, let's ensure the counts and selected images per label are consistent.\n",
        "I can actually change the target size if I want. Let's see how much time it takes for everything. Don't forget to a timer thingy to the\n",
        "above step. For now, manually write it.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "selected_images_list = list(selected_images)\n",
        "\n",
        "#final dictionary of selected images per label without duplicates\n",
        "final_selected_images_per_label = defaultdict(list)\n",
        "final_label_count = defaultdict(int)\n",
        "\n",
        "for image in selected_images_list:\n",
        "    image_labels = csv_data[csv_data['Image Index'] == image]['Finding Labels'].values[0].split('|')\n",
        "    for image_label in image_labels:\n",
        "        image_label = image_label.strip()\n",
        "        final_selected_images_per_label[image_label].append(image)\n",
        "        final_label_count[image_label] += 1\n",
        "\n",
        "print(\"Final Selected Images Count:\")\n",
        "for label, count in final_label_count.items():\n",
        "    print(f\"{label}: {count}\")\n",
        "\n",
        "print(f\"Total final selected images: {len(selected_images_list)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qU7Gyn9TQjtK",
        "outputId": "ca27cfb3-47c1-4df1-ef81-66c668524476"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Selected Images Count:\n",
            "No Finding: 900\n",
            "Pneumonia: 962\n",
            "Consolidation: 928\n",
            "Fibrosis: 938\n",
            "Infiltration: 1660\n",
            "Mass: 896\n",
            "Emphysema: 977\n",
            "Pneumothorax: 897\n",
            "Edema: 893\n",
            "Atelectasis: 1001\n",
            "Nodule: 852\n",
            "Cardiomegaly: 907\n",
            "Pleural_Thickening: 953\n",
            "Hernia: 227\n",
            "Effusion: 1401\n",
            "Total final selected images: 7501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#adjusting sampling for the oversampled ones.\n",
        "\n",
        "target_count_revised = 1000\n",
        "\n",
        "filtered_df = pd.DataFrame([(img, label) for label, images in final_selected_images_per_label.items() for img in images], columns=['Image Index', 'Label'])\n",
        "\n",
        "target_count_revised = 900\n",
        "oversampled_labels = {'Infiltration', 'Effusion'}\n",
        "\n",
        "final_selected_images = set(selected_images)\n",
        "label_counts = defaultdict(int, label_count)\n",
        "\n",
        "for label in oversampled_labels:\n",
        "    images_with_label = filtered_df[\n",
        "        filtered_df['Label'].str.contains(label) &\n",
        "        filtered_df['Label'].apply(lambda x: set(x.split('|')).issubset(oversampled_labels))\n",
        "    ]['Image Index'].unique()\n",
        "\n",
        "    for image_id in images_with_label:\n",
        "        if label_counts[label] <= target_count_revised:\n",
        "            break\n",
        "\n",
        "        final_selected_images.discard(image_id)\n",
        "        label_counts[label] -= 1\n",
        "\n",
        "print(\"Final Selected Images Count:\")\n",
        "for label, count in label_counts.items():\n",
        "    print(f\"{label}: {count}\")\n",
        "\n",
        "print(f\"Total selected images: {len(final_selected_images)}\")\n",
        "\n",
        "\n",
        "final_selected_indices_path = '/content/drive/My Drive/MLOPs Project/final_selected_indices.txt'\n",
        "with open(final_selected_indices_path, 'w') as f:\n",
        "    for index in final_selected_images:\n",
        "        f.write(f\"{index}\\n\")\n",
        "\n",
        "print(f\"Final selected indices saved to {final_selected_indices_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxIyqktaRNHY",
        "outputId": "bea34ca8-1614-451c-d58f-f3ee908b9fc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Selected Images Count:\n",
            "Hernia: 244\n",
            "Atelectasis: 1056\n",
            "Pneumothorax: 958\n",
            "Nodule: 900\n",
            "Consolidation: 1001\n",
            "Infiltration: 900\n",
            "Pneumonia: 1071\n",
            "Pleural_Thickening: 1035\n",
            "Mass: 957\n",
            "Effusion: 900\n",
            "Emphysema: 1046\n",
            "Cardiomegaly: 960\n",
            "Fibrosis: 999\n",
            "Edema: 989\n",
            "No Finding: 900\n",
            "Total selected images: 6241\n",
            "Final selected indices saved to /content/drive/My Drive/MLOPs Project/final_selected_indices.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# nihc Images actual sampling"
      ],
      "metadata": {
        "id": "FOZcKJfCjvuu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import time\n",
        "import urllib.request\n",
        "import tarfile"
      ],
      "metadata": {
        "id": "3HtFWPnJk_pK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_and_extract(zip_link, zip_file_name, extraction_folder, log_file):\n",
        "    log_message = f'Downloading {zip_file_name}...\\n'\n",
        "    with open(log_file, 'a') as log:\n",
        "        log.write(log_message)\n",
        "\n",
        "    urllib.request.urlretrieve(zip_link, zip_file_name)\n",
        "\n",
        "    log_message = 'Download complete.\\n'\n",
        "    with open(log_file, 'a') as log:\n",
        "        log.write(log_message)\n",
        "\n",
        "    log_message = f'Extracting {zip_file_name}...\\n'\n",
        "    with open(log_file, 'a') as log:\n",
        "        log.write(log_message)\n",
        "\n",
        "    os.makedirs(extraction_folder, exist_ok=True)\n",
        "    with tarfile.open(zip_file_name, 'r:gz') as tar:\n",
        "        tar.extractall(extraction_folder)\n",
        "\n",
        "    log_message = 'Extraction complete.\\n'\n",
        "    with open(log_file, 'a') as log:\n",
        "        log.write(log_message)\n",
        "\n",
        "\n",
        "def load_selected_indices(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        return set(line.strip() for line in f)\n",
        "\n",
        "\n",
        "def save_matching_images(extracted_folder, selected_indices, save_folder, log_file):\n",
        "    os.makedirs(save_folder, exist_ok=True)\n",
        "    saved_count = 0\n",
        "\n",
        "    for image_id in selected_indices:\n",
        "        image_name = image_id #already saved in .png format\n",
        "        extra= f\"images/{image_id}\"\n",
        "        image_path = os.path.join(extracted_folder, extra)\n",
        "\n",
        "        if os.path.exists(image_path):\n",
        "          shutil.copy(image_path, os.path.join(save_folder, image_name))\n",
        "          saved_count += 1\n",
        "          log_message = f'Saved image: {image_name}\\n'\n",
        "          with open(log_file, 'a') as log:\n",
        "              log.write(log_message)\n",
        "\n",
        "    log_message = f'Total images saved: {saved_count}\\n'\n",
        "    with open(log_file, 'a') as log:\n",
        "        log.write(log_message)\n",
        "\n",
        "    return saved_count\n",
        "\n",
        "\n",
        "def delete_extracted_images(extraction_folder, zip_file_path, log_file):\n",
        "    shutil.rmtree(extraction_folder)  # Removing the entire extracted folder - saving space. I ran out of memory while trying to download from hugging face\n",
        "    log_message = f'Extracted images deleted from {extraction_folder}\\n'\n",
        "\n",
        "    if os.path.exists(zip_file_path):\n",
        "        os.remove(zip_file_path)\n",
        "        log_message += f'Deleted zip file: {zip_file_path}\\n'\n",
        "    else:\n",
        "        log_message += f'Zip file not found: {zip_file_path}\\n'\n",
        "\n",
        "    with open(log_file, 'a') as log:\n",
        "        log.write(log_message)\n",
        "\n",
        "\n",
        "def get_directory_size(directory):\n",
        "    total_size = 0\n",
        "    for dirpath, dirnames, filenames in os.walk(directory):\n",
        "        for f in filenames:\n",
        "            fp = os.path.join(dirpath, f)\n",
        "            total_size += os.path.getsize(fp)\n",
        "    return total_size"
      ],
      "metadata": {
        "id": "94Vt1NO1ng2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive_save_folder = '/content/drive/My Drive/MLOPs Project/sampled_data' #folder where the final sampled data goes\n",
        "\n",
        "#these are mentioned in the nihc images folder in a file on how to access batches\n",
        "\"\"\"zip_links = [\n",
        "    'https://nihcc.box.com/shared/static/vfk49d74nhbxq3nqjg0900w5nvkorp5c.gz']\"\"\"\n",
        "\n",
        "zip_links = [\n",
        "    'https://nihcc.box.com/shared/static/vfk49d74nhbxq3nqjg0900w5nvkorp5c.gz',\n",
        "    'https://nihcc.box.com/shared/static/i28rlmbvmfjbl8p2n3ril0pptcmcu9d1.gz',\n",
        "    'https://nihcc.box.com/shared/static/f1t00wrtdk94satdfb9olcolqx20z2jp.gz',\n",
        "\t'https://nihcc.box.com/shared/static/0aowwzs5lhjrceb3qp67ahp0rd1l1etg.gz',\n",
        "    'https://nihcc.box.com/shared/static/v5e3goj22zr6h8tzualxfsqlqaygfbsn.gz',\n",
        "\t'https://nihcc.box.com/shared/static/asi7ikud9jwnkrnkj99jnpfkjdes7l6l.gz',\n",
        "\t'https://nihcc.box.com/shared/static/jn1b4mw4n6lnh74ovmcjb8y48h8xj07n.gz',\n",
        "    'https://nihcc.box.com/shared/static/tvpxmn7qyrgl0w8wfh9kqfjskv6nmm1j.gz',\n",
        "\t'https://nihcc.box.com/shared/static/upyy3ml7qdumlgk2rfcvlb9k6gvqq2pj.gz',\n",
        "\t'https://nihcc.box.com/shared/static/l6nilvfa9cg3s28tqv1qc1olm3gnz54p.gz',\n",
        "\t'https://nihcc.box.com/shared/static/hhq8fkdgvcari67vfhs7ppg2w6ni4jze.gz',\n",
        "\t'https://nihcc.box.com/shared/static/ioqwiy20ihqwyr8pf4c24eazhh281pbu.gz'\n",
        "]\n",
        "\n",
        "\n",
        "selected_indices_file = '/content/drive/My Drive/MLOPs Project/final_selected_indices.txt'\n",
        "selected_indices = load_selected_indices(selected_indices_file)\n",
        "\n",
        "\n",
        "log_file_path = '/content/drive/My Drive/MLOPs Project/image_sampling_log.txt'"
      ],
      "metadata": {
        "id": "r8JBHOsPn_eN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#os.makedirs(log_file_path, exist_ok=True) -- not required coz this is for creating a directory if it doesn't exist. Not for creating files.\n",
        "#by using with open like below, it automatically creates the log text file if it's not already present.\n",
        "\n",
        "with open(log_file_path, 'w') as log_file:\n",
        "    log_file.write('Image Processing Log\\n')\n",
        "    log_file.write('====================\\n')\n",
        "\n",
        "\n",
        "for idx, zip_link in enumerate(zip_links):\n",
        "    zip_file_name = f'images_{idx + 1:02d}.tar.gz'\n",
        "    extraction_folder = f'/content/extracted_images_{idx + 1:02d}'\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    download_and_extract(zip_link, zip_file_name, extraction_folder, log_file_path)\n",
        "    saved_count = save_matching_images(extraction_folder, selected_indices, drive_save_folder, log_file_path)\n",
        "\n",
        "    colab_used_space = get_directory_size('/content')\n",
        "    drive_used_space = get_directory_size(drive_save_folder)\n",
        "\n",
        "    log_message = f'Total space used in Colab: {colab_used_space / (1024 ** 2):.2f} MB\\n'\n",
        "    log_message += f'Total space used in Drive save folder: {drive_used_space / (1024 ** 2):.2f} MB\\n'\n",
        "\n",
        "    with open(log_file_path, 'a') as log:\n",
        "        log.write(log_message)\n",
        "\n",
        "    delete_extracted_images(extraction_folder, zip_file_name, log_file_path)\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    log_message = f'Time taken to process {zip_file_name}: {elapsed_time:.2f} seconds\\n'\n",
        "    log_message += '====================\\n\\n'\n",
        "\n",
        "    with open(log_file_path, 'a') as log:\n",
        "        log.write(log_message)\n",
        "\n",
        "    selected_indices = {img_id for img_id in selected_indices if f\"{img_id}.png\" not in os.listdir(drive_save_folder)}\n",
        "\n",
        "\n",
        "final_count_message = f'Final count of images saved: {len(os.listdir(drive_save_folder))}\\n'\n",
        "with open(log_file_path, 'a') as log:\n",
        "    log.write(final_count_message)\n"
      ],
      "metadata": {
        "id": "aqc7TOw-jhMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#12th file download code, as it was doing an infinite loop previously.\n",
        "import os\n",
        "import urllib.request\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "selected_indices_path = '/content/drive/My Drive/MLOPs Project/final_selected_indices.txt'\n",
        "save_folder = '/content/drive/My Drive/MLOPs Project/sampled_data'\n",
        "os.makedirs(save_folder, exist_ok=True)\n",
        "\n",
        "with open(selected_indices_path, 'r') as file:\n",
        "    selected_indices = set(line.strip() for line in file)\n",
        "\n",
        "last_url = 'https://nihcc.box.com/shared/static/ioqwiy20ihqwyr8pf4c24eazhh281pbu.gz'\n",
        "zip_file_name = 'images_12.tar.gz'\n",
        "\n",
        "print(f'Downloading {zip_file_name}...')\n",
        "urllib.request.urlretrieve(last_url, zip_file_name)\n",
        "\n",
        "print(f'Extracting {zip_file_name}...')\n",
        "with tarfile.open(zip_file_name, 'r:gz') as tar:\n",
        "    tar.extractall('/content/temp_images')\n",
        "\n",
        "\n",
        "extracted_folder = '/content/temp_images/images'\n",
        "for image_name in os.listdir(extracted_folder):\n",
        "    if image_name in selected_indices:\n",
        "        shutil.copy(os.path.join(extracted_folder, image_name), os.path.join(save_folder, image_name))\n",
        "        selected_indices.remove(image_name)\n",
        "\n",
        "\n",
        "shutil.rmtree('/content/temp_images')\n",
        "os.remove(zip_file_name)\n",
        "\n",
        "print(f'Finished processing {zip_file_name}. Remaining images to save: {len(selected_indices)}')\n",
        "print(\"Process complete.\")\n"
      ],
      "metadata": {
        "id": "1MOYQPZ_biFI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88b149ce-0b0e-4d2f-80e9-44a4c9e787aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading images_12.tar.gz...\n",
            "Extracting images_12.tar.gz...\n",
            "Finished processing images_12.tar.gz. Remaining images to save: 5852\n",
            "Process complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#debugging things\n",
        "\n",
        "def list_extracted_files(extracted_folder):\n",
        "  print(\"Available files in extracted folder:\")\n",
        "  extracted_files = os.listdir(extracted_folder)\n",
        "\n",
        "  i= 0\n",
        "  for filename in extracted_files:\n",
        "    file_path = os.path.join(extracted_folder, filename)\n",
        "    i += 1\n",
        "    if i < 5:\n",
        "      print(\"filename:\", filename)\n",
        "      print(file_path)\n",
        "\n",
        "\n",
        "    if filename == \"00000782_000.png\":\n",
        "        print(f\"Found specific file: {file_path}\")\n",
        "\n",
        "\n",
        "list_extracted_files('/content/extracted_images_01/images')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAGQV-MrxbwT",
        "outputId": "4eef336c-8652-4d20-a07e-ee6fdb654abf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available files in extracted folder:\n",
            "filename: 00000137_001.png\n",
            "/content/extracted_images_01/images/00000137_001.png\n",
            "filename: 00001029_016.png\n",
            "/content/extracted_images_01/images/00001029_016.png\n",
            "filename: 00001187_005.png\n",
            "/content/extracted_images_01/images/00001187_005.png\n",
            "filename: 00001092_000.png\n",
            "/content/extracted_images_01/images/00001092_000.png\n",
            "Found specific file: /content/extracted_images_01/images/00000782_000.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final csv with sampeled data labels"
      ],
      "metadata": {
        "id": "lPZoz8OVLqAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv"
      ],
      "metadata": {
        "id": "m5j3W_82Q6VK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saved_folder= '/content/drive/My Drive/MLOPs Project/sampled_data'\n",
        "saved_images_list= os.listdir(saved_folder)\n",
        "saved_images_list.sort()\n",
        "\n",
        "csv_file_path = '/content/drive/My Drive/MLOPs Project/Data_Entry.csv'\n",
        "csv_data = pd.read_csv(csv_file_path)"
      ],
      "metadata": {
        "id": "npfHYd7FLo4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_images= csv_data['Image Index'].to_list()\n",
        "all_labels= csv_data['Finding Labels'].to_list()\n",
        "\n",
        "one_hot_encoding= {\n",
        "    'No Finding': 0,\n",
        "    'Atelectasis': 1,\n",
        "    'Cardiomegaly': 2,\n",
        "    'Effusion': 3,\n",
        "    'Infiltration': 4,\n",
        "    'Mass': 5,\n",
        "    'Nodule': 6,\n",
        "    'Pneumonia': 7,\n",
        "    'Pneumothorax': 8,\n",
        "    'Consolidation': 9,\n",
        "    'Edema': 10,\n",
        "    'Emphysema': 11,\n",
        "    'Fibrosis': 12,\n",
        "    'Pleural_Thickening': 13,\n",
        "    'Hernia': 14\n",
        "}\n",
        "\n",
        "saved_labels_list= []\n",
        "i1= 0\n",
        "for i in saved_images_list:\n",
        "  if i in all_images:\n",
        "    i1+=1\n",
        "    labels= all_labels[all_images.index(i)].strip().split('|')\n",
        "    encoded_labels= [one_hot_encoding[i] for i in labels]\n",
        "    saved_labels_list.append(encoded_labels)\n",
        "print(\"mathced images:\", i1)\n",
        "\n",
        "rows= zip(saved_images_list, saved_labels_list)\n",
        "new_csv_path= '/content/drive/My Drive/MLOPs Project/sampled_data_entry.csv'\n",
        "\n",
        "with open(new_csv_path, 'w') as infile:\n",
        "  writer= csv.writer(infile)\n",
        "  writer.writerow([\"Image Index\", \"Labels\"])\n",
        "  writer.writerows(rows)\n",
        "\n"
      ],
      "metadata": {
        "id": "zIXQE3uMMyQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_images = csv_data['Image Index'].to_list()\n",
        "all_labels = csv_data['Finding Labels'].to_list()\n",
        "all_genders = csv_data['Patient Gender'].to_list()\n",
        "all_ages = csv_data['Patient Age'].to_list()\n",
        "\n",
        "\n",
        "one_hot_encoding = {\n",
        "    'No Finding': 0,\n",
        "    'Atelectasis': 1,\n",
        "    'Cardiomegaly': 2,\n",
        "    'Effusion': 3,\n",
        "    'Infiltration': 4,\n",
        "    'Mass': 5,\n",
        "    'Nodule': 6,\n",
        "    'Pneumonia': 7,\n",
        "    'Pneumothorax': 8,\n",
        "    'Consolidation': 9,\n",
        "    'Edema': 10,\n",
        "    'Emphysema': 11,\n",
        "    'Fibrosis': 12,\n",
        "    'Pleural_Thickening': 13,\n",
        "    'Hernia': 14\n",
        "}\n",
        "\n",
        "saved_data_list = []\n",
        "i1 = 0\n",
        "\n",
        "\n",
        "for i in saved_images_list:\n",
        "    if i in all_images:\n",
        "        i1 += 1\n",
        "        index = all_images.index(i)\n",
        "        labels = all_labels[index].strip().split('|')\n",
        "        gender = all_genders[index]\n",
        "        age = all_ages[index]\n",
        "\n",
        "        encoded_labels = [one_hot_encoding[label] for label in labels]\n",
        "\n",
        "        one_hot_vector = [0] * len(one_hot_encoding)\n",
        "        for label in encoded_labels:\n",
        "            one_hot_vector[label] = 1\n",
        "\n",
        "        saved_data_list.append([i, labels, gender, age, one_hot_vector])\n",
        "\n",
        "print(\"Matched images:\", i1)\n",
        "\n",
        "new_csv_path = '/content/drive/My Drive/MLOPs Project/sampled_data_entry.csv'\n",
        "\n",
        "with open(new_csv_path, 'w', newline='') as infile:\n",
        "    writer = csv.writer(infile)\n",
        "    writer.writerow([\"Image Index\", \"Labels\", \"Gender\", \"Age\", \"One-Hot Encoding\"])\n",
        "    writer.writerows(saved_data_list)\n",
        "\n",
        "print(f\"CSV file saved at {new_csv_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qH-dt-kjz0Yw",
        "outputId": "dd733a75-a13a-4077-875b-44470dd93275"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matched images: 6241\n",
            "CSV file saved at /content/drive/My Drive/MLOPs Project/sampled_data_entry.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Label - Indices file"
      ],
      "metadata": {
        "id": "U-1eiJU0YXi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import json\n",
        "from ast import literal_eval"
      ],
      "metadata": {
        "id": "36P9s0uPYgdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_csv_path= '/content/drive/My Drive/MLOPs Project/sampled_data_entry.csv'\n",
        "json_path= '/content/drive/My Drive/MLOPs Project/labels_to_indices.json'\n",
        "\n",
        "label_to_indices = {}\n",
        "\n",
        "with open(new_csv_path, \"r\") as infile:\n",
        "    reader = csv.DictReader(infile)\n",
        "    for row in reader:\n",
        "        index = row[\"Image Index\"]\n",
        "        labels = literal_eval(row[\"Labels\"])  # Converts string representation of list to an actual list\n",
        "\n",
        "        for label in labels:\n",
        "            if label not in label_to_indices:\n",
        "                label_to_indices[label] = []\n",
        "            label_to_indices[label].append(index)\n",
        "\n",
        "\n",
        "with open(json_path, mode=\"w\") as json_file:\n",
        "    json.dump(label_to_indices, json_file, indent=4)"
      ],
      "metadata": {
        "id": "IcFoYUlgYdMX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}