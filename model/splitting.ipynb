{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import pickle\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "TEHOI-LRJ0dQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_pickle_file = \"raw_compressed_data.pkl\"\n",
        "output_folder = \"output\""
      ],
      "metadata": {
        "id": "iHw1p9kvKrTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(input_pickle_file, 'rb') as f:\n",
        "      data = pickle.load(f)\n",
        "\n",
        "print(type(data))\n",
        "print(f\"Number of keys: {len(data)}\")\n",
        "print(\"Sample keys:\", list(data.keys())[:5])\n",
        "print(\"Sample value of the first key:\", data[list(data.keys())[0]])"
      ],
      "metadata": {
        "id": "L6ncs2bj7BF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spllitting pickle files"
      ],
      "metadata": {
        "id": "q-vLOPJ1vQ_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_pickle_data(pickle_file, output_folder, test_size=0.2, random_state=42):\n",
        "\n",
        "  i= 0\n",
        "\n",
        "  with open(pickle_file, 'rb') as f:\n",
        "      data = pickle.load(f)\n",
        "\n",
        "  print(type(data))\n",
        "  print(data)\n",
        "\n",
        "  if isinstance(data, dict):\n",
        "    keys = list(data.keys())\n",
        "    train_keys, test_keys = train_test_split(keys, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    train_data = {key: data[key] for key in train_keys}\n",
        "    for key in train_keys:\n",
        "      if i==1:\n",
        "        i+=1\n",
        "        print(key)\n",
        "        print(train_data[key])\n",
        "\n",
        "    test_data = {key: data[key] for key in test_keys}\n",
        "\n",
        "  elif isinstance(data, (list, tuple)):\n",
        "    train_data, test_data = train_test_split(data, test_size=test_size, random_state=random_state)\n",
        "\n",
        "  else:\n",
        "    raise ValueError(f\"Unsupported data type: {type(data)}. Only dictionaries and lists are supported.\")\n",
        "\n",
        "  #train_data, test_data = train_test_split(data, test_size=test_size, random_state=random_state)\n",
        "  os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "  train_pickle_file = f\"{output_folder}/train_data.pkl\"\n",
        "  with open(train_pickle_file, 'wb') as f:\n",
        "      pickle.dump(train_data, f)\n",
        "  print(f\"Train data saved to {train_pickle_file}\")\n",
        "  #files.download(train_pickle_file)\n",
        "\n",
        "  test_pickle_file = f\"{output_folder}/test_data.pkl\"\n",
        "  with open(test_pickle_file, 'wb') as f:\n",
        "      pickle.dump(test_data, f)\n",
        "  print(f\"Test data saved to {test_pickle_file}\")\n",
        "  #files.download(test_pickle_file)"
      ],
      "metadata": {
        "id": "qe-7QmgfvUe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_pickle_data(input_pickle_file, output_folder, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "XnT0V1txv8JJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split data into folders"
      ],
      "metadata": {
        "id": "yel59CPBvM5s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "go2qhp49Jtl9"
      },
      "outputs": [],
      "source": [
        "def split_data(csv_file, image_folder, output_folder, test_size=0.2, random_state=42):\n",
        "    \"\"\"\n",
        "    Splits images into training and testing folders based on a CSV file.\n",
        "\n",
        "    Args:\n",
        "        csv_file (str): Path to the CSV file with image metadata.\n",
        "        image_folder (str): Path to the folder containing images.\n",
        "        output_folder (str): Path to the output folder where 'train' and 'test' folders will be created.\n",
        "        test_size (float): Proportion of the dataset to include in the test split.\n",
        "        random_state (int): Random seed for reproducibility.\n",
        "    \"\"\"\n",
        "    data = pd.read_csv(csv_file, delimiter=',')\n",
        "    print(data.columns)\n",
        "    image_ids = data['Image Index'].values\n",
        "\n",
        "    train_ids, test_ids = train_test_split(image_ids, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    train_folder = os.path.join(output_folder, 'train')\n",
        "    test_folder = os.path.join(output_folder, 'test')\n",
        "\n",
        "    os.makedirs(train_folder, exist_ok=True)\n",
        "    os.makedirs(test_folder, exist_ok=True)\n",
        "\n",
        "    for img_id in train_ids:\n",
        "        src_path = os.path.join(image_folder, img_id)\n",
        "        dest_path = os.path.join(train_folder, img_id)\n",
        "        if os.path.exists(src_path):\n",
        "            shutil.copy(src_path, dest_path)\n",
        "\n",
        "    for img_id in test_ids:\n",
        "        src_path = os.path.join(image_folder, img_id)\n",
        "        dest_path = os.path.join(test_folder, img_id)\n",
        "        if os.path.exists(src_path):\n",
        "            shutil.copy(src_path, dest_path)\n",
        "\n",
        "    print(f\"Data split complete! Train folder: {train_folder}, Test folder: {test_folder}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_data(csv_file, image_folder, output_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKqyma9GKaYs",
        "outputId": "8f8725f6-b08f-4bdc-d5e4-17c68c266602"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Image Index', 'Labels', 'Gender', 'Age', 'One-Hot Encoding'], dtype='object')\n",
            "Data split complete! Train folder: /content/drive/My Drive/MLOPs Project/split_data/train, Test folder: /content/drive/My Drive/MLOPs Project/split_data/test\n"
          ]
        }
      ]
    }
  ]
}