{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "id": "WVqAGqq9eMfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import ast\n",
        "import torch\n",
        "import pickle\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import random_split, DataLoader, TensorDataset\n",
        "\n",
        "from torchmetrics.classification import MultilabelPrecision, MultilabelRecall, MultilabelF1Score"
      ],
      "metadata": {
        "id": "xIkVEDkEd2qY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_pickle = \"preprocessed_dummy_data.pkl\"\n",
        "model_path = \"final_model.pth\"\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "OALK6ZhqazYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohaLgMX6at8Q"
      },
      "outputs": [],
      "source": [
        "def load_test_data(original_data_pickle, batch_size, target_size=(224, 224)):\n",
        "\n",
        "  images = []\n",
        "  demographics = []\n",
        "  labels= []\n",
        "\n",
        "  resize_transform = transforms.Compose([\n",
        "      transforms.Resize(target_size),\n",
        "      transforms.ToTensor()\n",
        "  ])\n",
        "\n",
        "  with open(original_data_pickle, 'rb') as f:\n",
        "      data = pickle.load(f)\n",
        "\n",
        "  for item in data.values():\n",
        "\n",
        "    \"\"\"\n",
        "    The image data we get would be in bytes. We need to open it and convert it to grey scale and then resize. Recheck it. What are we doing with resizing before then?\n",
        "    \"\"\"\n",
        "    image_data = item['image_data']\n",
        "    image = Image.open(io.BytesIO(image_data)).convert('L')\n",
        "    image = resize_transform(image)  # Resizing and converting to tensor with shape (1, H, W) --> got an error without it\n",
        "\n",
        "    label= item['image_label']\n",
        "    label = ast.literal_eval(label)\n",
        "    label = np.array(label, dtype=int)\n",
        "\n",
        "    #considering test preprocessing would come from the actual preprocessing pipeline, I'm not doing the age and gender transformation here\n",
        "    age = torch.tensor([item['age']], dtype=torch.float32)\n",
        "    gender = torch.tensor(item['gender'], dtype=torch.float32)\n",
        "\n",
        "    images.append(image)\n",
        "    demographics.append(torch.cat([age, gender]))\n",
        "    labels.append(label)\n",
        "\n",
        "  \"\"\"\n",
        "  Stacking images and demographics.\n",
        "  images Shape: (num_samples, channels, height, width)\n",
        "  demographics Shape: (num_samples, num_features)\n",
        "  \"\"\"\n",
        "  images = torch.stack(images)\n",
        "  demographics = torch.stack(demographics)\n",
        "  labels = torch.stack([torch.tensor(label, dtype=torch.long) for label in labels])\n",
        "  #labels = torch.tensor(labels, dtype= torch.long)\n",
        "\n",
        "  test_dataset = TensorDataset(images, demographics, labels)\n",
        "  test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "  print(f\" samples: {len(test_dataset)}\")\n",
        "\n",
        "  return test_loader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomResNet18(nn.Module):\n",
        "    def __init__(self, demographic_fc_size, num_demographics, num_classes=15):\n",
        "        super(CustomResNet18, self).__init__()\n",
        "\n",
        "        self.resnet = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "\n",
        "        # Modifying the first convolutional layer to accept grayscale images (1 channel) --> generally ResNet expects 3 channels\n",
        "        #for RGB\n",
        "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "\n",
        "        # Removing the final fully connected layer in ResNet\n",
        "        self.resnet = nn.Sequential(*list(self.resnet.children())[:-1])\n",
        "\n",
        "        # this fc processes the demographics (age + gender)\n",
        "        self.demographics_fc = nn.Sequential(\n",
        "            nn.Linear(num_demographics, demographic_fc_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(512 + demographic_fc_size, num_classes)  # 512 from ResNet(it's how resnet is), 32 from demographics_fc, can make it 64?\n",
        "\n",
        "    def forward(self, images, demographics):\n",
        "        x = self.resnet(images)  # Passing images through the modified ResNet (without its last layer)\n",
        "        x = x.view(x.size(0), -1)  # Flattening the ResNet output\n",
        "\n",
        "        demographics_features = self.demographics_fc(demographics)\n",
        "        x = torch.cat((x, demographics_features), dim=1)\n",
        "\n",
        "        #print(\"Shape after concatenating demographics:\", x.shape)\n",
        "\n",
        "        x = self.fc(x)\n",
        "        #print(\"Output shape before returning:\", x.shape)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "x92zlqSidKzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(test_loader, model, criterion, precision_metric, recall_metric, f1_metric, confidence= 0.3):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    test_loss = 0.0\n",
        "\n",
        "    precision_metric.reset()\n",
        "    recall_metric.reset()\n",
        "    f1_metric.reset()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for inputs, demographics, labels in test_loader:\n",
        "        inputs, demographics, labels = inputs.to(device), demographics.to(device), labels.to(device)\n",
        "        outputs = model(inputs, demographics)\n",
        "\n",
        "        test_loss += criterion(outputs, labels.float()).item()\n",
        "\n",
        "        probabilities = torch.sigmoid(outputs)\n",
        "        predicted = (probabilities >= confidence).int()\n",
        "\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.numel()\n",
        "\n",
        "        #print(\"predicted:\", predicted)\n",
        "        #print(\"labels: \", labels)\n",
        "\n",
        "        precision_metric.update(predicted, labels)\n",
        "        recall_metric.update(predicted, labels)\n",
        "        f1_metric.update(predicted, labels)\n",
        "\n",
        "    test_accuracy = 100 * correct / total\n",
        "    precision = precision_metric.compute().item()\n",
        "    recall = recall_metric.compute().item()\n",
        "    f1_score = f1_metric.compute().item()\n",
        "    avg_test_loss = test_loss / len(test_loader)\n",
        "\n",
        "\n",
        "    print(f'Test Loss: {avg_test_loss:.4f}')\n",
        "    print(f'Test Accuracy: {test_accuracy:.2f}%')\n",
        "    print(f'Test Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1_score:.4f}')\n",
        "\n",
        "    return test_accuracy, precision, recall, f1_score"
      ],
      "metadata": {
        "id": "IIf1W6l_beAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "  config = {\n",
        "    \"file_path\": \"preprocessed_data_new.pkl\",\n",
        "    \"num_demographics\": 3,\n",
        "    \"num_classes\": 15,\n",
        "    \"train_percent\": 0.7,\n",
        "    \"val_percent\": 0.1\n",
        "  }\n",
        "\n",
        "  demographics_fc_size = 64\n",
        "\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "  print(\"Loading the best model for evaluation...\")\n",
        "\n",
        "  model = CustomResNet18(demographics_fc_size,\n",
        "                           num_demographics=config[\"num_demographics\"],\n",
        "                           num_classes=config[\"num_classes\"])\n",
        "  model.load_state_dict(torch.load(model_path))\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "\n",
        "  test_loader = load_test_data(test_data_pickle, batch_size)\n",
        "\n",
        "  precision_metric = MultilabelPrecision(num_labels= config[\"num_classes\"], average='macro').to(device)\n",
        "  recall_metric = MultilabelRecall(num_labels= config[\"num_classes\"], average='macro').to(device)\n",
        "  f1_metric = MultilabelF1Score(num_labels= config[\"num_classes\"], average='macro').to(device)\n",
        "\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "  test_accuracy, precision, recall, f1_score= evaluate_model(test_loader, model, criterion, precision_metric, recall_metric, f1_metric)\n",
        "\n",
        "  print(f\"Test Accuracy of the best model: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0EeaotgbkAl",
        "outputId": "1a23cf4f-2ec1-4c68-cba6-fcb7781e81eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the best model for evaluation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-966edffe538b>:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " samples: 50\n",
            "Test Loss: 0.3722\n",
            "Test Accuracy: 83.47%\n",
            "Test Precision: 0.0535, Recall: 0.1000, F1-score: 0.0559\n",
            "Test Accuracy of the best model: 83.4667\n"
          ]
        }
      ]
    }
  ]
}